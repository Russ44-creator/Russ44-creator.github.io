[{"title":"Tags","url":"/2023/09/21/14d342362f66aa86e2aa1c1e11aa1204/","content":"Research DiscoveryPersonal ProjectDaily LifeInsights\n"},{"title":"Some understanding of Shiro","url":"/2023/11/07/1b0a797ee682e571b9ca23871c09946e/","content":"This autumn, I embarked on a fascinating journey into the world of Shiro, a powerful and flexible framework for securing Java applications. Shiro, which means ‚Äúcastle‚Äù in Japanese, serves as a fortress for your applications, safeguarding them from unauthorized access and potential security vulnerabilities.\nMy Shiro learning experience has been both rewarding and enlightening. I delved into its features and found that it excels in handling authentication, authorization, and session management. With Shiro, I could easily secure my Java applications and protect sensitive data.\nOne of the highlights of my journey was learning how to configure Shiro‚Äôs security features with ease. Its simple, yet highly customizable configuration made it a joy to work with. I integrated Shiro into my application and set up authentication realms and permission sets, allowing for fine-grained control over user access.\nHere‚Äôs a glimpse of what I learned in code:\n    // Shiro INI configurationsecurityManager = org.apache.shiro.web.mgt.DefaultWebSecurityManagersecurityManager.realms = $myRealmmyRealm = com.example.MyRealmmyRealm.credentialsMatcher = $passwordMatcheruser123 = password123, adminguest = guestPassword, guest// Securing a web route with Shiro/login = authc/admin/** = authc, roles[admin]\n\nWith Shiro‚Äôs straightforward syntax, I could secure web routes, ensuring only authenticated users could access sensitive areas. I also learned how to protect specific routes based on user roles, granting or denying access accordingly.\nShiro‚Äôs session management was another vital aspect I explored. It offered a seamless way to handle user sessions, and I could easily configure session timeout, cookie settings, and session persistence options. This made my application not only secure but also user-friendly.\nIn conclusion, my autumn journey with Shiro has been an incredible learning experience. I‚Äôve gained a deeper understanding of application security and developed the skills to fortify my Java applications. Shiro‚Äôs flexibility and simplicity have made it a go-to choice for securing software, and I‚Äôm excited to continue honing my Shiro skills in the seasons to come. As the leaves change and autumn turns to winter, my commitment to safeguarding software remains as steadfast as ever.\n","categories":["Insights"],"tags":["Insights"]},{"title":"Elf Dynamic Linker","url":"/2023/09/23/3ecb9e75ca5ca9d3f65e40116c10e3e1/","content":"Elf Dynamic Linker\n","categories":["Personal Project"],"tags":["Personal Project"]},{"title":"Leveraging GraphQL for Efficient Data Retrieval in Your Application","url":"/2023/11/03/7bb42455df391b6407b7b1f596a2d6d0/","content":"In the ever-evolving landscape of web development, ensuring efficient data retrieval is crucial to creating high-performing and user-friendly applications. This is where GraphQL steps in, offering a versatile and powerful solution for managing data queries and retrieval.\nData Retrieval:\nOne of GraphQL‚Äôs standout features is its ability to allow frontend applications to request precisely the data they need, eliminating the over-fetching or under-fetching of data. This fine-grained control enables React components and other frontend technologies to use GraphQL queries to fetch specific fields or objects, aligning data retrieval with the component‚Äôs exact requirements. This not only optimizes data transfer but also enhances application performance.\nComponent Data Loading:\nGraphQL makes it possible to fetch necessary data when a component loads or mounts. This means that before a component even starts rendering, it already possesses the essential data it needs, ensuring a seamless and efficient user experience. With GraphQL, you can preload data into your components, minimizing the need for subsequent data requests during runtime.\nSharing Data Among Multiple Components:\nIn complex applications, multiple components often require access to the same data. GraphQL simplifies this process by allowing these components to share the same data query. As a result, you reduce data redundancy, save on resources, and ensure data consistency across different parts of your application.\nLazy Loading:\nGraphQL supports on-demand data loading, which is a powerful feature when dealing with large datasets. With GraphQL, you can fetch data only when the user explicitly requests it. This approach is in stark contrast to traditional REST APIs, which often return fixed data sets. Lazy loading not only boosts application performance but also results in more efficient use of server resources.\nData Caching:\nMany GraphQL client libraries, such as Apollo Client, come equipped with data caching capabilities. This feature allows you to cache data locally, reducing the need for repeated server requests. By caching data on the client side, your application can continue to function offline or with intermittent connectivity, delivering a smoother user experience.\nDynamic Data:\nOne of GraphQL‚Äôs powerful capabilities is its ability to handle dynamic data. By passing variables to GraphQL queries, you can dynamically construct queries based on user input or application state. This flexibility makes it easier to build dynamic and interactive applications that respond in real-time to user actions.\nConclusion:\nGraphQL is a game-changer when it comes to data retrieval in web applications. Its ability to optimize data fetching, enable lazy loading, support data caching, and accommodate dynamic data requirements makes it a valuable tool for enhancing the performance and user experience of modern web applications. With GraphQL, you can take your data retrieval strategies to the next level, providing users with fast and efficient access to the information they need.\n","categories":["Insights"],"tags":["Insights"]},{"title":"About Me","url":"/2023/09/21/81d9f505441078e06980e0bd02616e94/","content":"Self-Introduction\nHi, I‚Äôm Lingfeng Deng, a Computer Science graduate student at Brown University. I‚Äôm passionate about software engineering and have had the opportunity to work on some exciting projects. One of my recent internships was at SAP, where I developed automation suites using Pytest and Selenium to improve product reliability and implemented CI/CD pipelines for efficient software delivery. I also worked at GUYEE, where I collaborated on building a multi-field intelligent IoT platform for Volkswagen, enhancing factory management using technologies like Spring Boot and Vue.js. Currently, I‚Äôm involved in research projects at Brown University, including the development of PaSh, a tool for automating parallelization of POSIX shell scripts, and research on network protocols.I love tackling challenging problems and learning new technologies. Feel free to explore my GitHub and LinkedIn profiles to see more of my work. Let‚Äôs connect and chat about tech, coding, or anything else that interests you! üòÑ\n\nEducation\n2023-08 - 2025-05 Brown University\n2022-01 - 2022-05 University of Wisconsin, Madison\n2019-08 - 2023-05 Xi‚Äôan Jiaotong University\n2016-08 - 2019-06 Chengdu No.7 High School\n\nWork Experience\n2022-07 - 2022-12 SAP, Xi‚Äôan China\n\n\n"},{"title":"Hello World","url":"/2023/09/21/b10a8db164e0754105b7a99be72e3fe5/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n"},{"title":"Some understanding of MinIO","url":"/2023/11/08/b5097be8b9af2388b96e3a8679b05697/","content":"As the leaves began to change and the autumn breeze filled the air, I embarked on a journey to expand my knowledge by delving into the world of MinIO. This fall, I took on the challenge of learning how to harness the power of MinIO and integrate it seamlessly with Spring Boot applications. The experience has been both enlightening and rewarding.\nMinIO, an open-source object storage system, offers a scalable and high-performance solution for managing and storing vast amounts of unstructured data. My decision to explore MinIO was driven by its flexibility and the rising demand for reliable object storage solutions in the software development landscape.\nDuring my autumn learning journey, I discovered the beauty of MinIO‚Äôs simplicity. It provided me with an efficient way to manage objects and files while offering compatibility with various programming languages and frameworks. I also realized the significance of secure and distributed storage, making MinIO a versatile tool in modern software development.\nIntegrating MinIO with a Spring Boot application was a delightful challenge. The Spring Boot framework‚Äôs simplicity and MinIO‚Äôs easy-to-use APIs made the integration process smooth. With MinIO as the backing storage solution, I was able to build robust applications capable of handling large volumes of data efficiently.\nHere is a snippet of code showcasing how you can integrate MinIO with a Spring Boot application:\nimport io.minio.MinioClient;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class MinIOConfig &#123;    @Value(&quot;$&#123;minio.url&#125;&quot;)    private String minioUrl;    @Value(&quot;$&#123;minio.accessKey&#125;&quot;)    private String accessKey;    @Value(&quot;$&#123;minio.secretKey&#125;&quot;)    private String secretKey;    @Bean    public MinioClient minioClient() &#123;        return MinioClient.builder()                .endpoint(minioUrl)                .credentials(accessKey, secretKey)                .build();    &#125;&#125;\nIn this code, we set up a Spring Boot configuration class to create a MinioClient bean with the necessary credentials. This allows us to use MinIO for object storage within our Spring Boot application.\nThe combination of MinIO and Spring Boot empowers developers to build applications with seamless and reliable object storage capabilities. Whether you‚Äôre working on a photo-sharing app, a document management system, or any application that deals with large files, this integration can provide a scalable and efficient solution.\nAs the autumn season draws to a close, I‚Äôm grateful for the opportunity to learn and apply MinIO in my software development projects. The knowledge gained during this journey will undoubtedly continue to benefit my future endeavors in the world of software development. Learning MinIO and integrating it with Spring Boot has been a rewarding experience, expanding my skill set and enhancing the quality of my software applications.\n","categories":["Insights"],"tags":["Insights"]},{"title":"Some understanding of Kubernetes","url":"/2023/11/08/b941bed889f00cfb3874fa32a5e2eeff/","content":"Kubernetes, often abbreviated as K8s, is an open-source container orchestration platform that has revolutionized the way we manage, scale, and deploy containerized applications. In this blog post, we‚Äôll delve into the fundamental features and functionality of Kubernetes and provide a basic configuration example to get you started.\nKey Features of Kubernetes:Container Orchestration: Kubernetes excels at managing and orchestrating containerized applications. It automates tasks like deployment, scaling, and load balancing.\nAutomated Load Balancing: It distributes incoming traffic across your application‚Äôs pods, ensuring even workload distribution and high availability.\nSelf-healing: Kubernetes can automatically replace or reschedule containers that fail, ensuring your application is always available.\nScalability: Easily scale your application up or down based on demand. Kubernetes can handle changes in traffic by adjusting the number of running containers.\nService Discovery: Kubernetes provides a built-in DNS for easy service discovery, making it simple for one service to locate and communicate with another.\nConfiguration Management: Manage application configurations separately from the code. Kubernetes uses ConfigMaps and Secrets for this purpose.\nBasic Kubernetes Configuration:\nLet‚Äôs walk through a simple example of deploying a ‚ÄúHello World‚Äù application using Kubernetes. Below is a YAML configuration file for a basic deployment:\napiVersion: apps/v1kind: Deploymentmetadata:  name: hello-world-deploymentspec:  replicas: 3  selector:    matchLabels:      app: hello-world  template:    metadata:      labels:        app: hello-world    spec:      containers:        - name: hello-world-container          image: nginx:latest          ports:            - containerPort: 80\nThis configuration defines a Deployment with three replicas running an Nginx ‚ÄúHello World‚Äù container.\nTo deploy this configuration, save it to a file (e.g., hello-world-deployment.yaml) and use the kubectl command:\nkubectl apply -f hello-world-deployment.yaml\nKubernetes will create the specified number of replicas and manage their lifecycle. You can access the application by exposing it through a service or an Ingress resource.\nThis example barely scratches the surface of what Kubernetes can do. As you continue your Kubernetes journey, you‚Äôll explore more advanced features like pods, services, volumes, and advanced deployment strategies. Kubernetes offers a powerful and flexible platform for managing containerized applications, making it a cornerstone in modern DevOps and container orchestration.\nKubernetes is a versatile platform with a rich feature set that simplifies container management, scaling, and deployment. This blog post provides a glimpse into its basic features and offers a simple configuration example. As you explore Kubernetes further, you‚Äôll uncover its full potential for orchestrating complex containerized applications at scale. \n","categories":["Insights"],"tags":["Insights"]},{"title":"Categories","url":"/2023/09/21/d0771a42bbc49a6941f59913fcda35e3/","content":"Research DiscoveryPersonal ProjectDaily LifeInsights\n"},{"title":"CS Fundamentals","url":"/2023/11/14/d1936e71f9c98f8d01c158b63ba6ff13/","content":"What is the difference between SQL and NoSQL? And how to scale them?SQL (Structured Query Language):\n\nData Model: SQL databases are relational and use a structured schema, with tables defining the relationships between different entities.\nScalability: Scaling SQL databases is typically achieved through vertical scaling (adding more resources to a single server). This can involve increasing CPU, RAM, or storage capacity.\n\nNoSQL:\n\nData Model: NoSQL databases can have various data models, including document-oriented, key-value pairs, wide-column stores, or graph databases. They are more flexible and don‚Äôt require a fixed schema.\nScalability: NoSQL databases are often designed for horizontal scalability. This involves adding more servers to a distributed database system to handle increased load. NoSQL databases can scale out by adding more nodes to a cluster.\n\nScaling Strategies:\n\nSQL Scaling: Vertical scaling involves upgrading a single server‚Äôs capacity (e.g., increasing CPU, RAM). However, there‚Äôs a limit to how much a single server can handle. Distributed SQL databases and sharding can also be employed for horizontal scaling, but these approaches can be complex.\n\nNoSQL Scaling: NoSQL databases are often designed for horizontal scaling from the beginning. This can be achieved by adding more servers to a cluster, distributing the data across nodes. Sharding and replication are common techniques in NoSQL databases for achieving scalability.\n\n\nSummary:\n\nSQL databases are relational, use structured schemas, and typically scale vertically.\nNoSQL databases offer more flexibility in data models and are designed for horizontal scalability, making them well-suited for distributed systems.\n\nRemember, the choice between SQL and NoSQL depends on the specific needs of the application, the nature of the data, and the scalability requirements.\nDifference Between Process and Thread:\nDefinition:\n\nA process is an independent program with its own memory space and resources. It runs in isolation from other processes.\nA thread is the smallest unit of execution within a process. Threads within the same process share the same memory space and resources.\n\n\nIsolation:\n\nProcesses are independent and have separate memory spaces. One process cannot directly access the memory of another process.\nThreads share the same memory space within a process and can directly access shared data.\n\n\nResource Overhead:\n\nCreating a new process is resource-intensive as it involves duplicating the entire memory space of the parent process.\nCreating a new thread is less resource-intensive, as it involves duplicating only the essential resources needed for the thread to run.\n\n\nCommunication:\n\nProcesses communicate through inter-process communication mechanisms such as message passing or shared files.\nThreads communicate through shared data. However, careful synchronization is required to avoid data corruption.\n\n\nFault Tolerance:\n\nIf one process fails, it does not directly impact other processes. Processes are more isolated.\nIf one thread crashes in a process, it can potentially affect the entire process since threads share the same resources.\n\n\n\nRelation Between Process and Thread:\n\nHierarchical Structure:\n\nA process can contain multiple threads. These threads share the same resources, but each has its own execution path.\nThreads within the same process can communicate more easily than processes, as they share the same memory space.\n\n\nConcurrency:\n\nProcesses and threads provide a way to achieve concurrency in a program. Multiple processes or threads can execute independently, improving overall system performance.\n\n\nResource Sharing:\n\nThreads within a process share the same resources, making it efficient for communication and data sharing.\nProcesses, being more isolated, may use inter-process communication mechanisms for resource sharing.\n\n\nParallelism:\n\nProcesses are more suited for parallelism as they can run on multiple processors independently.\nThreads are more lightweight and may not be as well-suited for parallelism, especially if the underlying hardware does not support it.\n\n\n\nIn summary, a process is a standalone program with its own memory space, while a thread is a unit of execution within a process, sharing the same resources. Threads provide a way to introduce concurrency within a process, making it possible to perform multiple tasks simultaneously. Processes and threads complement each other in designing and implementing concurrent and parallel systems.\n","categories":["Insights"],"tags":["Insights"]},{"title":"Some understanding of CTF","url":"/2023/10/31/d3cfd76d0cd2f20149ade1f88ebe5486/","content":"Capture the Flag (CTF) competitions are becoming an increasingly popular way for cybersecurity enthusiasts to test and improve their skills. CTFs involve participants solving challenges and puzzles in categories like cryptography, reverse engineering, web exploitation, and binary exploitation, in order to capture ‚Äúflags‚Äù which are often in the form of codes or keys. Successfully capturing flags demonstrates a mastery of various cybersecurity concepts and techniques.\nWhile CTFs originate from the information security community, they provide valuable experience for any software developer looking to improve their security skills. Here are some reasons why CTFs and software security are worth understanding for any programmer:\nReal-world experience - CTF challenges are based on vulnerabilities and techniques used by hackers in the wild. Participating in CTFs gives you hands-on experience dealing with common software exploits like SQL injection, cross-site scripting, buffer overflows, etc. Identifying and patching these vulnerabilities will make you a better developer.Learn cybersecurity fundamentals - Core infosec concepts like encryption, hashes, encoding, cryptography, binaries, networking, and more are central to solving CTF challenges. Mastering these foundational building blocks is key for writing secure code.Gain offensive security insights - To find flaws and holes in CTF challenges, you need to think like an attacker and understand offensive security methodologies. This knowledge enables you to build robust systems capable of withstanding real hacking attempts.Practice makes perfect - The more CTFs you participate in, the better you get at things like quickly analyzing unknown code, identifying vulnerabilities, making connections, and finding creative solutions. These coding and problem-solving skills transfer directly to software development.Compete and benchmark skills - CTFs allow you to test your abilities against security experts around the world. Seeing how you rank compared to others can help motivate further learning and identify areas in need of improvement.While CTFs can involve some specialized security skills like expertise in certain tools or technical protocols, the core concepts align closely with secure coding best practices. Learning through CTF challenges helps instill the mindset and thought processes necessary for writing robust, hack-resistant software.\n","categories":["Insights"],"tags":["Insights"]},{"title":"ÊµãËØïÊñáÁ´†","url":"/2022/03/17/eb1908cb6cc7c14ffa02a18a052710e9/","content":"ÊµãËØïÊëòË¶ÅÔºÅÔºÅ\n\n\nÊ†áÈ¢ò‰∏Ä‰Ω†Â•ΩÔºå‰∏ñÁïåÔºÅ\n‰ª£Á†Å‰∏Äecho &quot;hello world!!&quot;\n\nË°®Ê†º‰∏Ä\n\n\nÊ†áÈ¢ò1\nÊ†áÈ¢ò2\nÊ†áÈ¢ò3\n\n\n\n1\n1\n1\n\n\n2\n2\n2\n\n\n3\n3\n3\n\n\nÊµÅÁ®ãÂõæsequenceDiagram\n    Â∞èÁ®ãÂ∫è ->> Â∞èÁ®ãÂ∫è : wx.login()Ëé∑Âèñcode\n    Â∞èÁ®ãÂ∫è ->> + ÊúçÂä°Âô® : wx.request()ÂèëÈÄÅcode\n    ÊúçÂä°Âô® ->> + ÂæÆ‰ø°ÊúçÂä°Âô® : code+appid+secret\n    ÂæÆ‰ø°ÊúçÂä°Âô® -->> - ÊúçÂä°Âô® : openid\n    ÊúçÂä°Âô® ->> ÊúçÂä°Âô® : Ê†πÊçÆopenidÁ°ÆÂÆöÁî®Êà∑Âπ∂ÁîüÊàêtoken\n    ÊúçÂä°Âô® -->> - Â∞èÁ®ãÂ∫è : token\n\n\nflowchart LR\nA[Hard] -->|Text| B(Round)\nB --> C{Decision}\nC -->|One| D[Result 1]\nC -->|Two| E[Result 2]\n\n\n\n\nst=>start: Start:> http://www.google.com[blank]\ne=>end: End :>http://www.google.com\nop1=>operation: My Operation\nsub1=>subroutine: My Subroutine\ncond=>condition: Yes\nor No?:>http://www.google.com\nio=>inputoutput: catch something...\npara=>parallel: parallel tasks\n\nst->op1->cond\ncond(yes)->io->e\ncond(no)->para\npara(path1, bottom)->sub1(right)->op1\npara(path2, top)->op1{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12}  var code = document.getElementById(\"flowchart-0-code\").value;  var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value));  var diagram = flowchart.parse(code);  diagram.drawSVG(\"flowchart-0\", options);st=>start: Start|past:>http://www.google.com[blank]\ne=>end: End:>http://www.google.com\nop1=>operation: My Operation|past\nop2=>operation: Stuff|current\nsub1=>subroutine: My Subroutine|invalid\ncond=>condition: Yes\nor No?|approved:>http://www.google.com\nc2=>condition: Good idea|rejected\nio=>inputoutput: catch something...|request\n\nst->op1(right)->cond\ncond(yes, right)->c2\ncond(no)->sub1(left)->op1\nc2(yes)->io->e\nc2(no)->op2->e{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12}  var code = document.getElementById(\"flowchart-1-code\").value;  var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-1-options\").value));  var diagram = flowchart.parse(code);  diagram.drawSVG(\"flowchart-1\", options);","categories":["ÊµãËØï"],"tags":["ÊµãËØï"]},{"title":"Some Understanding of Service Layer, Controller Layer and DAO Layer","url":"/2023/11/09/ed6ba32b9b335592cc15de37a0539cdb/","content":"In a Spring Boot project, the architecture is often structured into three layers: Controller, Service, and Dao. Each layer plays a distinct role in maintaining the separation of concerns, ensuring a clean and scalable codebase.\nController:The Controller layer serves as the entry point for handling incoming requests. It is responsible for processing user input, interacting with the Service layer, and returning an appropriate response to the client. Controllers are the bridge between the user interface and the underlying business logic.\n@RestController@RequestMapping(&quot;/api&quot;)public class MyController &#123;    @Autowired    private MyService myService;    @GetMapping(&quot;/endpoint&quot;)    public ResponseEntity&lt;String&gt; handleRequest() &#123;        // Process the request and delegate business logic to the service layer        String result = myService.processRequest();        return ResponseEntity.ok(result);    &#125;&#125;\n\nService:The Service layer contains the business logic of the application. It encapsulates complex operations and coordinates data flow between the Controller and the Dao layer. This layer promotes reusability and modularity by keeping the business rules separate from the presentation layer.\n@Servicepublic class MyService &#123;    @Autowired    private MyDao myDao;    public String processRequest() &#123;        // Business logic implementation, possibly involving data retrieval from the Dao layer        return &quot;Processed result&quot;;    &#125;&#125;\n\nDao:The Dao (Data Access Object) layer is responsible for interacting with the database or any other external data source. It abstracts the details of data access, allowing the Service layer to focus on business logic. By isolating database operations, the Dao layer facilitates easier maintenance and testing.\n@Repositorypublic class MyDao &#123;    @Autowired    private JdbcTemplate jdbcTemplate;    public String fetchData() &#123;        // Data retrieval logic using JDBC or an ORM framework        return jdbcTemplate.queryForObject(&quot;SELECT data FROM my_table&quot;, String.class);    &#125;&#125;\n\nIn this way, the three layers work collaboratively to ensure a well-organized and maintainable Spring Boot project. The Controller handles user input and output, the Service layer manages business logic, and the Dao layer takes care of data access. This separation of concerns enhances code readability, testability, and overall project scalability.\n","categories":["Insights"],"tags":["Insights"]}]